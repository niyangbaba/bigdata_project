声明：仅供参考，切记照搬！！！！！！
==============================公司基本信息=================================================
公司基本信息：
公司名称：南京途牛科技有限公司
地址：南京市玄武区玄武大道699-32号途牛大厦
公司部门：人事，财务，商务，研发（数据部），市场.....
数据部门：7人左右
如何分工：老大，数据采集，数据清洗预处理，数据分析与建模，前后端
================================途牛旅游数据分析平台===========================================
项目名称：途牛旅游数据分析平台

项目介绍：该项目采用大数据对用户行为数据以及多维度度数据进行分析，最终实现通过对旅游目的地、旅游舆情、旅游客流量、客源地、景区、游客和旅游关注度等
多角度、全方位的实时数据分析，为企业决策提供准确的数据支持和更真实、更可靠、更直观的决策依据。

主要的技术：flume+kafka+hdfs+hive+spark+hbase+mysql(注意:要记住使用的软件版本)

项目流程：1，通过js埋点采集pc端数据 或 java采集无线端的日志发送到nginx日志服务器上
          2，使用flume采集多个nginx日志服务器上的日志，发送到消息中间件kafka
          3，使用flume将kafka上的日志发送到hdfs上
          4，使用spark-core对保存在hdfs上的日志做数据清洗，保存到Hbase
          5，使用hive对Hbase中的数据进行预处理，将数据保存到hive中做多次分析计算
          6，使用spark-core对保存到Hbase中的数据或使用spark-sql对hive中的预处理数据进行分析计算，将分析后的结果保存到mysql中
          7，使用spark-Streaming对保存在kafka中的数据进行实时计算，将计算完的结果保存到msyql，hbase，或redis中
          9，web前端数据可视化

关键技术点：1，日志收集业务事件分析
            2，flume日志采集，agent高可靠和负载均衡
            2，封装了JdbcHelper
            3，自定义累加器
            4，二次排序
            5，spark-core的性能调优
            6，sql的开窗函数
            7，自定义UDAF函数
            9，spark-streaming Receiver如何保证数据不丢失以及提高读取效率
            11，spark-streaming和kafka进行连接，两种连接方式的区别
            12，如何手动管理消费偏移量
            13，自定义了kafkaManger（核心）
            14，讲解了如何灵活使用updateStateByKey算子
            15，如何使用fastJson
            16，如何使用spark-core将数据写入到hbase
            17，如何使用spark-core将从hbase中读取数据
            18，Utils常用的方法

关键指标：
https://www.sensorsdata.cn/demo/demo.html
https://mobile.umeng.com/analytics?spm=a211g2.182258.0.0.704497610dCLDH
https://mtj.baidu.com/web/demo/visit/page?appId=468475

1，流量指标：
               1.1 按时间维度,地域维度
                   会话个数 跳出数 页面流量
               1.2 会话session访问时长和步长占比
               1.3 访客来源分析（百度，自有流量，广告..）

2，计算每个地区点击,下单，支付次数排名top5的品类
            （计算下单,支付次数排名top5的地区或城市）

3，用户指标
              3.1  新增用户 活跃用户
              3.2  新老访客占比
              3.3  用户忠诚度(使用频次25/30，停留时间10/20，访问深度8/10，下单次数20/40) 63

4，转化率
             4.1 用户注册转化率
             4.2 下单转化率，支付转化率


5，无线端
            app启动次数（时间，地域）
            app用户活跃度（时间，地域）
            版本分布
            更多指标参考


数据量：
累计用户：2000W
活跃用户DAU：%8 160W
pv：1600W
单条日志大小：一条日志 2k
总共大小：16000000*2=32000000K=31250M=30G
提交的job数量：15


项目：使用scala语言编写，大概有90个scala类文件，每个任务文件大概200行左右，有30多张结果表



集群规模（仅供参考）：
我们用到集群10台
配置：10*64core*128G*2TB
分配：3台kafka，7 hadoop spark












